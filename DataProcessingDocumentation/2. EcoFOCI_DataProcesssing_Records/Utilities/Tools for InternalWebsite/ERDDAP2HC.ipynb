{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d770d15-ca8c-44ab-bef1-07e506ba6a4d",
   "metadata": {},
   "source": [
    "# ERDDAP to HighCharts Translator\n",
    "\n",
    "- Can be run on preliminary or final data\n",
    "- creates measurement type groups (temp, sal, oxy, chlor)\n",
    "\n",
    "These should be explorable from a deployment map (and maybe the log sheets).  The goal is to get a dynamic view of the data from the instruments at a site.\n",
    "\n",
    "Other ways to show information is instrument by instrument (this is done in the QC STAGE to evaluate corresponding issues - like sal/temp spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2fceb35-3441-46b7-9a68-263bea13ce15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import EcoFOCIpy.io.erddap as erddapy\n",
    "from erddapy import ERDDAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc255908-73d7-405b-8166-a6dd6b9b4d97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "status_dic = {'final':{'url':\"http://ecofoci-field.pmel.noaa.gov:8080/erddap\",'filename':'.csv','dataset':'datasets_Mooring_22bs2c_final'},\n",
    "          'prelim':{'url':\"http://ecofoci-field.pmel.noaa.gov:8082/erddap\",'filename':'_prelim.csv','dataset':'datasets_Mooring_22bs2c_preliminary'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64650960-b8ff-4448-a5f4-1f0c0d23bade",
   "metadata": {},
   "source": [
    "### Looped Code to do all moorings (first final and then prelim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8dba398-e2ab-4bf2-a2bc-fcf54cedda03",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tag = 'datasets_Mooring_24'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "165b3018-d4cb-45fc-a4b9-d53f7825dea3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets_Mooring_24bs2c_final\n",
      "datasets_Mooring_24bs4a_final\n",
      "datasets_Mooring_24bs8a_final\n",
      "datasets_Mooring_24bspr2a_final\n",
      "datasets_Mooring_24cb1a_final\n",
      "datasets_Mooring_24ckp1a_final\n",
      "datasets_Mooring_24ckp2a_final\n",
      "datasets_Mooring_24ckp3a_final\n",
      "datasets_Mooring_24kum2a_final\n",
      "datasets_Mooring_24sh1a_final\n",
      "datasets_Mooring_24upp3a_final\n",
      "datasets_Mooring_24bsitaer8a_final\n"
     ]
    }
   ],
   "source": [
    "### do all moorings\n",
    "\n",
    "status = 'final'\n",
    "e = ERDDAP(server=status_dic[status]['url'])\n",
    "df_ds = pd.read_csv(e.get_search_url(response='csv', search_for=f'final {dataset_tag}'))\n",
    "\n",
    "for dataset_id in df_ds['Dataset ID']:\n",
    "    print(dataset_id)\n",
    "    e = ERDDAP(server=status_dic[status]['url'],\n",
    "              protocol='tabledap',\n",
    "              response='csv')\n",
    "\n",
    "    e.dataset_id=dataset_id\n",
    "    \n",
    "    pdf = e.to_pandas(\n",
    "                index_col='time (UTC)',\n",
    "                parse_dates=True,\n",
    "                skiprows=(1,),  # units information can be dropped.\n",
    "                low_memory=False\n",
    "            )\n",
    "    pdf.columns = [x.split(' ')[0] for x in pdf.columns]\n",
    "    pdf.index.name = 'time'\n",
    "    \n",
    "    datalabel = dataset_id.split('_')[2]\n",
    "    # for parameter in ['temperature','salinity','chlorophyll_fluorescence']:\n",
    "    for parameter in ['temperature','salinity','chlor_fluorescence','chlorophyll_fluorescence','oxygen_concentration']:\n",
    "        try:\n",
    "            xdf = pdf[[parameter,'timeseries_id']].pivot_table(index='time', columns=['timeseries_id']).resample('1h').median().interpolate(limit=3).xs(parameter, axis=1, drop_level=True)\n",
    "            xdf.columns.rename(\"\",inplace=True)\n",
    "            xdf.index = xdf.index.tz_localize(None)\n",
    "            xdf.round(3).to_csv(f'{datalabel}_{parameter}.csv')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8cd76b2-aab7-4563-a1ed-88eea87bda36",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets_Mooring_24bs2c_preliminary\n",
      "datasets_Mooring_24bs4a_preliminary\n",
      "datasets_Mooring_24bs8a_preliminary\n",
      "datasets_Mooring_24cb1a_preliminary\n",
      "datasets_Mooring_24sh1a_preliminary\n",
      "datasets_Mooring_24bsitaer8a_preliminary\n",
      "datasets_Mooring_24bspr2a_preliminary\n",
      "datasets_Mooring_24ckp1a_preliminary\n",
      "datasets_Mooring_24ckp2a_preliminary\n",
      "datasets_Mooring_24ckp3a_preliminary\n",
      "datasets_Mooring_24kum2a_preliminary\n",
      "datasets_Mooring_24upp3a_preliminary\n"
     ]
    }
   ],
   "source": [
    "### do all moorings in prelim\n",
    "\n",
    "status = 'prelim'\n",
    "e = ERDDAP(server=status_dic[status]['url'])\n",
    "df_ds = pd.read_csv(e.get_search_url(response='csv', search_for=f'preliminary {dataset_tag}'))\n",
    "\n",
    "for dataset_id in df_ds['Dataset ID']:\n",
    "    if not dataset_id in ['']:\n",
    "        print(dataset_id)\n",
    "        e = ERDDAP(server=status_dic[status]['url'],\n",
    "                  protocol='tabledap',\n",
    "                  response='csv')\n",
    "    \n",
    "        e.dataset_id=dataset_id\n",
    "    \n",
    "        pdf = e.to_pandas(\n",
    "                    index_col='time (UTC)',\n",
    "                    parse_dates=True,\n",
    "                    skiprows=(1,),  # units information can be dropped.\n",
    "                    low_memory=False  \n",
    "                )\n",
    "        pdf.columns = [x.split(' ')[0] for x in pdf.columns]\n",
    "        pdf.index.name = 'time'\n",
    "        \n",
    "        datalabel = dataset_id.split('_')[2]\n",
    "        # for parameter in ['temperature','salinity','chlorophyll_fluorescence']:\n",
    "        for parameter in ['temperature','salinity','chlor_fluorescence','chlorophyll_fluorescence','oxygen_concentration']:\n",
    "            try:\n",
    "                xdf = pdf[[parameter,'timeseries_id']].pivot_table(index='time', columns=['timeseries_id']).resample('1h').median().interpolate(limit=3).xs(parameter, axis=1, drop_level=True)\n",
    "                xdf.columns.rename(\"\",inplace=True)\n",
    "                xdf.index = xdf.index.tz_localize(None)\n",
    "                xdf.round(3).to_csv(f'{datalabel}_{parameter}_prelim.csv')\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e40317-40de-44b5-81cf-61ed1829c038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:p312]",
   "language": "python",
   "name": "conda-env-p312-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
