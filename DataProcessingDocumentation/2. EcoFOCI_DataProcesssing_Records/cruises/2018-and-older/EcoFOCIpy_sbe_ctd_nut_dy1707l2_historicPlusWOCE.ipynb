{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11f9bcf2-bc74-4794-923c-dda60b50829d",
   "metadata": {},
   "source": [
    "# Using EcoFOCIpy to process raw field data\n",
    "\n",
    "## Cruise ID - DY1707l2\n",
    "\n",
    "## BTL Data + Nutrient Data\n",
    "\n",
    "This is a streamlined version of generation routines to merge bottle data and Mordy Nut. Lab Nutrient Data for long term archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "studied-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import EcoFOCIpy.io.sbe_ctd_parser as sbe_ctd_parser #<- instrument specific\n",
    "import EcoFOCIpy.io.ncCFsave as ncCFsave\n",
    "import EcoFOCIpy.metaconfig.load_config as load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "offensive-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_dir = '/Users/bell/ecoraid/2017/CTDcasts/dy1707l1/' #root path to cruise directory\n",
    "ecofocipy_dir = '/Users/bell/Programs/EcoFOCIpy/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "third-yellow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/bell/ecoraid/2017/CTDcasts/dy1707l1/rawconverted/ctd001.btl\n",
      "Processing /Users/bell/ecoraid/2017/CTDcasts/dy1707l1/rawconverted/ctd002.btl\n",
      "Processing /Users/bell/ecoraid/2017/CTDcasts/dy1707l1/rawconverted/ctd003.btl\n",
      "Processing /Users/bell/ecoraid/2017/CTDcasts/dy1707l1/rawconverted/ctd004.btl\n",
      "Processing /Users/bell/ecoraid/2017/CTDcasts/dy1707l1/rawconverted/ctd005.btl\n",
      "Processing /Users/bell/ecoraid/2017/CTDcasts/dy1707l1/rawconverted/ctd006.btl\n",
      "Processing /Users/bell/ecoraid/2017/CTDcasts/dy1707l1/rawconverted/ctd007.btl\n",
      "Processing /Users/bell/ecoraid/2017/CTDcasts/dy1707l1/rawconverted/ctd008.btl\n",
      "Processing /Users/bell/ecoraid/2017/CTDcasts/dy1707l1/rawconverted/ctd010.btl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/sbe_ctd_parser.py:91: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  ctd_df = pd.concat([ctd_df,row])\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/sbe_ctd_parser.py:91: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  ctd_df = pd.concat([ctd_df,row])\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/sbe_ctd_parser.py:91: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  ctd_df = pd.concat([ctd_df,row])\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/sbe_ctd_parser.py:91: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  ctd_df = pd.concat([ctd_df,row])\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/sbe_ctd_parser.py:91: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  ctd_df = pd.concat([ctd_df,row])\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/sbe_ctd_parser.py:91: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  ctd_df = pd.concat([ctd_df,row])\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/sbe_ctd_parser.py:91: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  ctd_df = pd.concat([ctd_df,row])\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/sbe_ctd_parser.py:91: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  ctd_df = pd.concat([ctd_df,row])\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/sbe_ctd_parser.py:91: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  ctd_df = pd.concat([ctd_df,row])\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "# edit to point to {cruise sepcific} raw datafiles \n",
    "datafile = sample_data_dir+'rawconverted/' #<- point to cruise and process all files within\n",
    "nutdatafile = sample_data_dir+'working/DiscreteNutrients/DY1707 Nutrient Data.csv' #<- point to cruise and process all files within\n",
    "cruise_name = 'dy1707l1' #no hyphens\n",
    "cruise_meta_file = sample_data_dir+'logs/DY1707L1.yaml'\n",
    "inst_meta_file = sample_data_dir+'logs/FOCI_standard_CTDpNutsWOCE.yaml' #<- copy to each deployment for simplicity?\n",
    "group_meta_file = ecofocipy_dir+'staticdata/institutional_meta_example.yaml'\n",
    "###############################################################\n",
    "\n",
    "#init and load data\n",
    "cruise = sbe_ctd_parser.sbe_btl()\n",
    "filename_list = sorted(glob.glob(datafile + '*.btl'))\n",
    "\n",
    "cruise_data = cruise.manual_parse(filename_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8e6cdca-77bf-47fd-a96c-94df03d1268b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbeox0ps</th>\n",
       "      <th>sbeox0ml/l</th>\n",
       "      <th>sbox0mm/kg</th>\n",
       "      <th>density00</th>\n",
       "      <th>density11</th>\n",
       "      <th>sbeox1ps</th>\n",
       "      <th>sbeox1ml/l</th>\n",
       "      <th>sbox1mm/kg</th>\n",
       "      <th>fleco-afl</th>\n",
       "      <th>sal00</th>\n",
       "      <th>sal11</th>\n",
       "      <th>t090c</th>\n",
       "      <th>t190c</th>\n",
       "      <th>times</th>\n",
       "      <th>prdm</th>\n",
       "      <th>par</th>\n",
       "      <th>scan</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bottle</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>97.045</td>\n",
       "      <td>6.2425</td>\n",
       "      <td>272.134</td>\n",
       "      <td>1024.4762</td>\n",
       "      <td>1024.4679</td>\n",
       "      <td>97.112</td>\n",
       "      <td>6.2469</td>\n",
       "      <td>272.324</td>\n",
       "      <td>1.8187</td>\n",
       "      <td>31.8270</td>\n",
       "      <td>31.8162</td>\n",
       "      <td>10.0823</td>\n",
       "      <td>10.0817</td>\n",
       "      <td>608.250</td>\n",
       "      <td>3.181</td>\n",
       "      <td>202.42</td>\n",
       "      <td>14599.0</td>\n",
       "      <td>2017-08-22 01:12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>96.745</td>\n",
       "      <td>6.2235</td>\n",
       "      <td>271.303</td>\n",
       "      <td>1024.4832</td>\n",
       "      <td>1024.4759</td>\n",
       "      <td>96.781</td>\n",
       "      <td>6.2258</td>\n",
       "      <td>271.406</td>\n",
       "      <td>1.8358</td>\n",
       "      <td>31.8268</td>\n",
       "      <td>31.8161</td>\n",
       "      <td>10.0805</td>\n",
       "      <td>10.0743</td>\n",
       "      <td>609.958</td>\n",
       "      <td>4.696</td>\n",
       "      <td>138.33</td>\n",
       "      <td>14640.0</td>\n",
       "      <td>2017-08-22 01:12:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sbeox0ps  sbeox0ml/l  sbox0mm/kg  density00  density11  sbeox1ps  \\\n",
       "bottle                                                                     \n",
       "1.0       97.045      6.2425     272.134  1024.4762  1024.4679    97.112   \n",
       "2.0       96.745      6.2235     271.303  1024.4832  1024.4759    96.781   \n",
       "\n",
       "        sbeox1ml/l  sbox1mm/kg  fleco-afl    sal00    sal11    t090c    t190c  \\\n",
       "bottle                                                                          \n",
       "1.0         6.2469     272.324     1.8187  31.8270  31.8162  10.0823  10.0817   \n",
       "2.0         6.2258     271.406     1.8358  31.8268  31.8161  10.0805  10.0743   \n",
       "\n",
       "          times   prdm     par     scan            datetime  \n",
       "bottle                                                       \n",
       "1.0     608.250  3.181  202.42  14599.0 2017-08-22 01:12:00  \n",
       "2.0     609.958  4.696  138.33  14640.0 2017-08-22 01:12:02  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cruise_data['ctd001.btl']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b1db20-be06-4d55-bfa6-f3d0018e28b0",
   "metadata": {},
   "source": [
    "## Load csv Nutrient File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0fb5c09-d76d-455c-89f4-3ba6a7954f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6r/n_mpcj7d7pdf9ncqvjy5vb8c0000jm/T/ipykernel_68429/1253400260.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  nut_data = pd.read_csv(nutdatafile,delimiter='\\t|,')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cruise</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Niskin</th>\n",
       "      <th>PO4 (uM)</th>\n",
       "      <th>Sil (uM)</th>\n",
       "      <th>NO3 (uM)</th>\n",
       "      <th>NO2 (uM)</th>\n",
       "      <th>NH4 (uM)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dy1707</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.144</td>\n",
       "      <td>14.9</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dy1707</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.052</td>\n",
       "      <td>13.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dy1707</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.937</td>\n",
       "      <td>11.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dy1707</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.876</td>\n",
       "      <td>11.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dy1707</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.817</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>dy1707</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>1.026</td>\n",
       "      <td>16.6</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>dy1707</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.817</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>dy1707</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>0.585</td>\n",
       "      <td>11.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>dy1707</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>0.583</td>\n",
       "      <td>11.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>dy1707</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>0.579</td>\n",
       "      <td>11.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cruise  Cast  Niskin  PO4 (uM)  Sil (uM)  NO3 (uM)  NO2 (uM)  NH4 (uM)\n",
       "0    dy1707     2       1     1.144      14.9       9.4      0.39      0.40\n",
       "1    dy1707     2       2     1.052      13.7       7.7      0.40      0.59\n",
       "2    dy1707     2       3     0.937      11.8       5.0      0.37      1.00\n",
       "3    dy1707     2       4     0.876      11.9       4.3      0.36      1.05\n",
       "4    dy1707     2       5     0.817      10.1       3.2      0.31      0.95\n",
       "..      ...   ...     ...       ...       ...       ...       ...       ...\n",
       "123  dy1707    18       7     1.026      16.6       9.8      0.18      0.10\n",
       "124  dy1707    18       8     0.817      14.1       6.4      0.11      0.13\n",
       "125  dy1707    18       9     0.585      11.8       2.6      0.03      0.06\n",
       "126  dy1707    18      10     0.583      11.8       2.6      0.03      0.07\n",
       "127  dy1707    18      11     0.579      11.8       2.6      0.02      0.09\n",
       "\n",
       "[128 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nut_data = pd.read_csv(nutdatafile,delimiter='\\t|,')\n",
    "nut_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f462e88-398a-4cd4-99de-afdae6763949",
   "metadata": {},
   "source": [
    "## Merge Bottle and Nutrient Data but drop non nutrient vars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "586c00a1-4b89-4488-927c-a9d84df24225",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keep_param = ['bottle','prdm']\n",
    "# keep_param = ['bottle','prsm']\n",
    "# keep_param = ['bottle','depsm']\n",
    "\n",
    "for cast,cdata in cruise_data.items():\n",
    "    try:\n",
    "        matchcast = int((cast.split('.')[0]).lower().split('ctd')[-1])\n",
    "        cruise_data[cast] = pd.merge(nut_data[nut_data['Cast']==matchcast],\n",
    "                                      cdata.reset_index()[keep_param],\n",
    "                                      right_on='bottle',\n",
    "                                      left_on='Niskin').set_index('bottle').drop(columns=['Cast'])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc88693f-5574-4ecc-ad61-d1a2940a9dca",
   "metadata": {},
   "source": [
    "## Add Deployment meta information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "freelance-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just a dictionary of dictionaries - simple\n",
    "with open(cruise_meta_file) as file:\n",
    "    cruise_config = yaml.full_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c37778a-8d12-44d0-b880-9af8f45bdbcb",
   "metadata": {},
   "source": [
    "## Add Instrument meta information\n",
    "\n",
    "Time, depth, lat, lon should be added regardless (always our coordinates) but for a mooring site its going to be a (1,1,1,t) dataset\n",
    "The variables of interest should be read from the data file and matched to a key for naming.  That key is in the inst_config file seen below and should represent common conversion names in the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "checked-raise",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(inst_meta_file) as file:\n",
    "    inst_config = yaml.full_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbb6352-448c-4f30-927b-a940fd9b866a",
   "metadata": {},
   "source": [
    "## Add institutional meta-information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24b2c8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(group_meta_file) as file:\n",
    "    group_config = yaml.full_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21621ffe-c41e-430c-a57b-fbb7fddbbd91",
   "metadata": {},
   "source": [
    "## Save CF Netcdf files\n",
    "\n",
    "Currently stick to netcdf3 classic... but migrating to netcdf4 (default) may be no problems for most modern purposes.  Its easy enough to pass the `format` kwargs through to the netcdf api of xarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "modular-volunteer",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 001\n",
      "Skipping 010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/ncCFsave.py:320: UserWarning: Times can't be serialized faithfully to int64 with requested units 'days since 1900-01-01'. Resolution of 'minutes' needed. Serializing times to floating point instead. Set encoding['dtype'] to integer dtype to serialize to int64. Set encoding['dtype'] to floating point dtype to silence this warning.\n",
      "  xdf.to_netcdf(filename,format=kwargs['format'],encoding={'time':{'units':'days since 1900-01-01'}})\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/ncCFsave.py:320: UserWarning: Times can't be serialized faithfully to int64 with requested units 'days since 1900-01-01'. Resolution of 'minutes' needed. Serializing times to floating point instead. Set encoding['dtype'] to integer dtype to serialize to int64. Set encoding['dtype'] to floating point dtype to silence this warning.\n",
      "  xdf.to_netcdf(filename,format=kwargs['format'],encoding={'time':{'units':'days since 1900-01-01'}})\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/ncCFsave.py:320: UserWarning: Times can't be serialized faithfully to int64 with requested units 'days since 1900-01-01'. Resolution of 'minutes' needed. Serializing times to floating point instead. Set encoding['dtype'] to integer dtype to serialize to int64. Set encoding['dtype'] to floating point dtype to silence this warning.\n",
      "  xdf.to_netcdf(filename,format=kwargs['format'],encoding={'time':{'units':'days since 1900-01-01'}})\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/ncCFsave.py:320: UserWarning: Times can't be serialized faithfully to int64 with requested units 'days since 1900-01-01'. Resolution of 'minutes' needed. Serializing times to floating point instead. Set encoding['dtype'] to integer dtype to serialize to int64. Set encoding['dtype'] to floating point dtype to silence this warning.\n",
      "  xdf.to_netcdf(filename,format=kwargs['format'],encoding={'time':{'units':'days since 1900-01-01'}})\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/ncCFsave.py:320: UserWarning: Times can't be serialized faithfully to int64 with requested units 'days since 1900-01-01'. Resolution of 'minutes' needed. Serializing times to floating point instead. Set encoding['dtype'] to integer dtype to serialize to int64. Set encoding['dtype'] to floating point dtype to silence this warning.\n",
      "  xdf.to_netcdf(filename,format=kwargs['format'],encoding={'time':{'units':'days since 1900-01-01'}})\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/ncCFsave.py:320: UserWarning: Times can't be serialized faithfully to int64 with requested units 'days since 1900-01-01'. Resolution of 'minutes' needed. Serializing times to floating point instead. Set encoding['dtype'] to integer dtype to serialize to int64. Set encoding['dtype'] to floating point dtype to silence this warning.\n",
      "  xdf.to_netcdf(filename,format=kwargs['format'],encoding={'time':{'units':'days since 1900-01-01'}})\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/ncCFsave.py:320: UserWarning: Times can't be serialized faithfully to int64 with requested units 'days since 1900-01-01'. Resolution of 'minutes' needed. Serializing times to floating point instead. Set encoding['dtype'] to integer dtype to serialize to int64. Set encoding['dtype'] to floating point dtype to silence this warning.\n",
      "  xdf.to_netcdf(filename,format=kwargs['format'],encoding={'time':{'units':'days since 1900-01-01'}})\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/ncCFsave.py:320: UserWarning: Times can't be serialized faithfully to int64 with requested units 'days since 1900-01-01'. Resolution of 'minutes' needed. Serializing times to floating point instead. Set encoding['dtype'] to integer dtype to serialize to int64. Set encoding['dtype'] to floating point dtype to silence this warning.\n",
      "  xdf.to_netcdf(filename,format=kwargs['format'],encoding={'time':{'units':'days since 1900-01-01'}})\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/ncCFsave.py:320: UserWarning: Times can't be serialized faithfully to int64 with requested units 'days since 1900-01-01'. Resolution of 'minutes' needed. Serializing times to floating point instead. Set encoding['dtype'] to integer dtype to serialize to int64. Set encoding['dtype'] to floating point dtype to silence this warning.\n",
      "  xdf.to_netcdf(filename,format=kwargs['format'],encoding={'time':{'units':'days since 1900-01-01'}})\n"
     ]
    }
   ],
   "source": [
    "#loop over all casts and perform tasks shown above\n",
    "\n",
    "for cast in cruise_data.keys():\n",
    "    try:\n",
    "        cruise_data[cast] = cruise_data[cast].rename(columns={\n",
    "                            'Sil (uM)':'SI',\n",
    "                            'PO4 (uM)':'PO4',\n",
    "                            'NO2 (uM)':'NO2', \n",
    "                            'NO3 (uM)':'NO3',\n",
    "                            'NH4 (uM)':'NH4',\n",
    "                            'Sil Flag':'SI_WOCE_FLAG',\n",
    "                            'PO4 Flag':'PO4_WOCE_FLAG',\n",
    "                            'NO2 Flag':'NO2_WOCE_FLAG', \n",
    "                            'NO3 Flag':'NO3_WOCE_FLAG',\n",
    "                            'NH4 Flag':'NH4_WOCE_FLAG',\n",
    "                            'Niskin':'BTLID',\n",
    "                            'prdm':'pressure',\n",
    "                            'prsm':'pressure',\n",
    "                            'empty':'empty', #this will be ignored\n",
    "                            'flag':'flag'})\n",
    "\n",
    "        cruise_data_nc = ncCFsave.EcoFOCI_CFnc(df=cruise_data[cast], \n",
    "                                    instrument_yaml=inst_config, \n",
    "                                    operation_yaml=cruise_config,\n",
    "                                    operation_type='ctd')\n",
    "\n",
    "        cruise_data_nc.expand_dimensions(dim_names=['latitude','longitude','time'],geophys_sort=False)\n",
    "\n",
    "        cruise_data_nc.variable_meta_data(variable_keys=list(cruise_data[cast].columns.values),drop_missing=False)\n",
    "        #adding dimension meta needs to come after updating the dimension values... BUG?\n",
    "        cruise_data_nc.dimension_meta_data(variable_keys=['time','latitude','longitude'])\n",
    "        cruise_data_nc.temporal_geospatioal_meta_data_ctd(positiveE=False,conscastno=cast.split('.')[0])\n",
    "\n",
    "        #add global attributes\n",
    "        cruise_data_nc.deployment_meta_add(conscastno=cast.split('.')[0].upper())\n",
    "\n",
    "        #add instituitonal global attributes\n",
    "        cruise_data_nc.institution_meta_add(group_config)\n",
    "\n",
    "        #add creation date/time - provenance data\n",
    "        cruise_data_nc.provinance_meta_add()\n",
    "\n",
    "        #provide intial qc status field\n",
    "        cruise_data_nc.qc_status(qc_status='excellent') #<- options are unknown, excellent, probably good, mixed, unqcd\n",
    "\n",
    "        cast = cast.lower().split('d')[-1].split('.')[0]\n",
    "        cruise_data_nc.xarray2netcdf_save(xdf = cruise_data_nc.get_xdf(),\n",
    "                                   filename=cruise_name+'c'+cast.zfill(3)+'_nut.nc',format=\"NETCDF3_CLASSIC\")\n",
    "    except:\n",
    "        os.remove(cruise_name+'c'+cast.zfill(3)+'_nut.nc')\n",
    "        print(f'Skipping {cast}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde49e5d-195d-403e-82fa-62550986fe4b",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "QC of data (plot parameters with other instruments)\n",
    "- be sure to updated the qc_status and the history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f9aa7e-324e-4088-83f0-6509d0a02a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:p312]",
   "language": "python",
   "name": "conda-env-p312-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
